## 背景

目前大多数PHM中数据驱动方法都是在同一个假设前提下提出的，即**仅在训练和测试数据集服从相同的分布下成立**。在实际工业场景下，环境噪声和操作条件的变化不可避免地使训练和测试数据的分布特征不同，因此很难保证机器学习模型在测试集和实际生产中的泛化性。

为了解决复杂工况导致的DFD问题，通常使用领域自适应技术。领域自适应的任务涉及到属于源域和目标域的两个数据集，我们在目标域与源域上拥有相似的任务与目标，但是目标域与源域中的数据具有不同的特征分布，这与我们之前的论述一致。领域自适应的最终目标是减少源域与目标域的分布差异，并利用源域中包含的知识改进目标域预测模型的性能。

基于这一出发点，提出了Deep wcDAN（working-condition-based Deep Domain Adaptation Network, Deep wcDAN）模型，该模型基于迁移学习中的领域自适应技术，并且提出了两种模式的基于工况的样本特征差异的度量方法，将该差异作为损失函数的一项，缩小了训练集与测试集的分布差异，提升了故障预测模型的泛化性，克服传统方法在复杂工况导致的分布不同条件下预测准确性受影响的问题。最后在CMAPSS数据集上，对提出模型进行了评估，并与前人的工作进行了对比。

## 模型

![](https://raw.githubusercontent.com/yshuyan/Picture/master/img/20200623104811.png)

首先，利用Deep CNN-LSTM构建框架的基准模型。该基准集成多层CNN和LSTM，可以自动学习数据的时序特征。之后提出了一个具有两种模式的wcMMD（working-condition Maximum Mean Discrepancy, wcMMD）特征差异计算方法，以最小化源域和目标域相同工况条件下样本的特征分布差异。Deep wcDAN的架构如图3-1所示。我们使用CNN从原始多维传感器数据中提取潜在特征。之后，这些特征被输入到多层LSTM中，最后由多层全连接层作为输出。为了提高模型的泛化效果，采用了领域自适应技术。在训练阶段，来自训练集和测试集的数据都被输入到模型中。我们通过添加wcMMD项来重新定义最终的损失函数，以减少CNN从两个域提取的特征之间的分布差异。

## 代码

### 安装  

XXXX

### 目录树

XXXXX

### 代码调用

#### Tips

XXX

## 结果展示 

### 数据集

| 数据集   | FD001 | FD002 | FD003 | FD004 |
| -------- | ----- | ----- | ----- | ----- |
| 训练集   | 100   | 260   | 100   | 249   |
| 测试集   | 100   | 259   | 100   | 248   |
| 工况数目 | 1     | 6     | 1     | 6     |
| 故障模式 | 1     | 1     | 2     | 2     |

每个数据集都是多维时间变量序列，每个时间节点下包括21维不同的传感器数据，以及3维工况参数，用以设置不同的工况和故障模式。在训练数据集中，时间序列是完整的从初始运行到故障的时间轨迹，而在测试数据集中，时间序列在故障之前的某个点开始记录，可能处于健康的初始阶段，也可能是运行过程中的某个点。我们的目标是利用提出的模型来预测给定序列末端的RUL值。  

表中FD001训练集共有100个完整的机器由健康到故障的时间序列，每个时间序列由时间长度不等的多维传感器数据组成。FD001测试集共有100个不完整的机器使用过程中的时间序列组成，起始点不定，在终止点机器是否有故障未知，我们的目标是预测这100个时间序列最后一个时间节点的RUL值。FD001和FD002中只有1种故障模式，FD003和FD004中有两种故障模式，不过故障模式不是本研究的研究重点，其对本研究的影响有限。

每个时间节点下传感器数据共包含26列：第一列是发动机序号，第2列是该时间节点处于本运行周期的位置，第3-5列是工况参数（对发动机性能有实质性影响），第6-26列是传感器数据。该数据集共有4个子数据集：FD001、FD002、FD003、FD004。其中依据先验知识，FD001与FD003的机器运行在一种工况条件下。而FD002和FD004依据3维工况参数进行k-means聚类工作在6种工况条件下。  

### 结果

> RMSE 指标对比

|                | FD001 | FD002 | FD003 | FD004 |
| -------------- | ----- | ----- | ----- | ----- |
| SVR            | 20.96 | 42.00 | 21.05 | 45.35 |
| RVR            | 23.80 | 31.30 | 22.37 | 34.34 |
| DCNN           | 18.45 | 30.29 | 19.82 | 29.16 |
| MODBNE         | 17.96 | 28.06 | 19.41 | 29.45 |
| CNN-LSTM       | 15.72 | 28.27 | 15.39 | 26.63 |
| CNN-LSTM(DA)   | 14.40 | 27.23 | 14.32 | 26.69 |
| Deep wcDAN(p1) | -     | 26.93 | -     | 26.42 |
| Deep wcDAN(p2) | -     | 27.14 | -     | 26.49 |

> Score 指标对比  

|                | FD001 | FD002  | FD003 | FD004  |
| -------------- | ----- | ------ | ----- | ------ |
| SVR            | 1382  | 589900 | 1598  | 371140 |
| RVR            | 1503  | 17423  | 1432  | 26509  |
| DCNN           | 1287  | 13570  | 1596  | 7886   |
| MODBNE         | 640   | 10851  | 683   | 7210   |
| CNN-LSTM       | 312   | 11732  | 345   | 6670   |
| CNN-LSTM(DA)   | 290   | 9869   | 316   | 6594   |
| Deep wcDAN(p1) | -     | 7441   | -     | 5380   |
| Deep wcDAN(p2) | -     | 8640   | -     | 5480   |

> 迁移效果展示  

![](https://raw.githubusercontent.com/yshuyan/Picture/master/img/20200623105526.png)

每个点的颜色表示引擎在某个时间点的RUL大小。我们可以通过参考每个图右边的彩色条来了解不同颜色代表的RUL取值。当颜色从上到下变化时，RUL值变小。每个子图的横坐标和纵坐标都是t-SNE生成的二维数据，没有具体含义，仅用于可视化。

我们可以看到，在相同的工况条件下，不同模型在训练数据集上的特征分布更加相似，如图(a)、(b)和(c)所示。但是，如果我们不采用Deep wcDAN模型，或者不考虑工况条件，如图(d)和(e)所示，测试数据集上的特征分布会与训练集上的分布显示出较大的差异，不能像训练数据集那样相同工况的样本紧密地聚集在一起。训练数据集和测试数据集之间的分布差异无疑会影响最终预测结果。如图(f)所示，当我们采用wcMMD对领域自适应流程进行优化后，性能得到了很大的提升。在相同的工况条件下，测试数据集上的特征分布和训练数据集上的特征分布更加一致。在减少相同工况条件下的训练数据集与测试数据集之间的距离的同时，增加了不同工况条件下的训练数据集与测试数据集之间的距离。结果表明，Deep wcDAN模型在测试数据集上的性能优于CNN-LSTM(DA)。
